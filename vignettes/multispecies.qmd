---
title: "Multispecies Distribution Modeling with caretSDM"
author: "Luíz Fernando Esser"
format: html
editor: visual
---

## Introduction

`caretSDM` is a under development R package that uses the powerful `caret` package as the main engine to obtain Species Distribution Models. One of its main attributes is the strong geoprocessing underlying its functions. Here we show how to model species distributions using `caretSDM` through the function `sdm_area` with a polygon. We will also show how to apply a PCA in predictors and scenarios to avoid multicolinearity. The aim of this modeling will be to obtain the distribution of *Araucaria angustifolia*, *Ilex paraguariensis* and *Myrceugenia euosma*, three co-occurring tree species.

First, we need to open our libraries.

```{r libraries}
library(caretSDM)
library(stars) # Package used to manipulate GIS data
library(dplyr) # Package to improve data handling
```

## Pre-Processing

To obtain models, we will need climatic data and species records. To easily obtain these data, we have two functions: `WorldClim_data` function downloads climatic variables from WorldClim 2.1, a widely used open-source database; in the same way, `GBIF_data` function downloads species records from GBIF, also a widely used open-source database. You can read more about them by running in the console `?GBIF_data` and `?WorldClim_data`.

### Obtaining species records

A easy way to get species data using `caretSDM` is the function `GBIF_data`, which retrieves species records from GBIF. Understandably, there are other sources of species data available, as well as our own data that can be the result of field work. In this sense, one can import to R it's own data in multiple ways, but be sure that the table will have three columns: species, decimalLongitude and decimalLatitude. `GBIF_data` function can retrieve the data ready to be included in caretSDM, thus if you have any doubt on how to format your own data, use `GBIF_data` function with the parameter `as_df = TRUE` to retrieve an example table.

```{r}
oc <- GBIF_data(c("Araucaria angustifolia", "Ilex paraguariensis", "Myrceugenia euosma"))
```

### Obtaining climatic data

We will first download and import current data, which is used to build the models. `WorldClim_data` function has an argument to set the directory in which you want to save the files. If you don't set it, files will be saved in your working directory (run `getwd()` to find out your working directory) in the folder "input_data/WorldClim_data_current/". If period is set to "future", then it is saved in "input_data/WorldClim_data_future/". We could run this script with a smaller resolution, but as the aim here is to show how the package works, we will use a resolution of 10 arc-minutes, which is very coarse, but quicker to download and run.

```{r WorldClim_data_current}
# Download current bioclimatic variables
WorldClim_data(period = "current", resolution = 10)

# Import current bioclimatic variables to R
pred <- read_stars(list.files("input_data/WorldClim_data_current/", full.names = T), along = "band", normalize_path = F)

# See what is inside pred
pred
```

### Defining the study area

A important step on model building in Species Distribution Models, is the definition of accessible area (the M in BAM diagram). This area can be, in Geographical Information Systems terms, as an example, the delimitation of a habitat (polygon) or a river basin network (lines). Another broadly used approach is the use of buffers around presences. The buffer size translates the potential distribution capabilities of a species. To educational purposes we will use a simple shape with Parana state boundaries that is available in caretSDM in the `parana` object.

In `caretSDM` there is a function that groups all the transformations regarding the study area to build and project the models. The `sdm_area` function is this function and is also responsible to check CRSs and create a grid to build models. This grid may seem unpurposed for terrestrial ecologists, but is a key element when modeling continental aquatic environments. `sdm_area` class will also keep the environmental/climatic data (*i.e.* "predictor variables", "covariates", "explanatory variables", "features" or "control variables"). With this class we will perform analysis using only the predictors (such as predictors transformations).

```{r}
# Create a sdm_area object
sa <- sdm_area(parana, cell_size = 20000, crs = 6933)
sa
plot_grid(sa)
```

Now that we have a study area, we can assign predictor variables and scenarios to it.

```{r add_predictors1}
# Add predictor variables into sdm_area
sa <- add_predictors(sa, pred)
sa
```

```{r add_scenarios}
sa <- add_scenarios(sa)
sa
```

Usually, we will need to subset variables that will inform our model. This can be due to statistical artifacts that are common in quarter bioclimatic variables, or a causation subset, aiming for those variables with causality effect on species distribution.

```{r select_preds}
# Select predictors
sa <- select_predictors(sa, paste0("X", 1:19, ".tif"))
sa <- set_predictor_names(sa, paste0("bio",1:19))
sa
```

```{r}
write_grid(sa, path = "results/grid_study_area.csv", centroid = TRUE)
write_grid(sa, path = "results/grid_study_area.gpkg", centroid = TRUE)
write_grid(sa, path = "results/grid_study_area.shp", centroid = TRUE)
```

```{r add_predictors}
mapview_predictors(sa)
```

### Defining the occurrences set in the study area

As `caretSDM` has a strong GIS background, it is necessary to explicitly tell which CRS is your data in. This will assure that every GIS transformation is correct. This step also assigns occurrences into a study area, excluding records outside the study area or with NAs in predictors. `occurrences_sdm` function creates a occurrences class (*i.e.* "response variable", "target" or "label") that will be used in occurrences transformations and functions, as pseudoabsences generation. As we used GBIF_data, which

```{r occurrences_sdm}
# Join occurrences to the study area
oc <- oc |>
  join_area(sa)
oc
```

### The `input_sdm` class

In `caretSDM` we use multiple classes to perform our analysis. Every time we perform a new analysis, objects keep the information of what we did. Ideally, the workflow will have only one object throughout it. The `input_sdm` class is the key class in the workflow, where every function will orbitate. That class puts occurrences, predictors, scenarios, models and predictions together to perform analysis that are only possible when two or more of these classes are available. First, we create the object by informing the occurrences and sdm_area.

```{r input_sdm}
i <- input_sdm(oc, sa)
i
```

```{r}
write_occurrences(i, path = "results/occurrences.csv", grid = FALSE)
write_occurrences(i, path = "results/occurrences.gpkg", grid = TRUE)
write_occurrences(i, path = "results/occurrences.shp", grid = TRUE)
```

Now we can visualize `oc` data using plot:

```{r plot_occurrences}
plot_occurrences(i)
```

### Data cleaning routine

As the first step in our workflow with the `input_sdm` object, we will clean our occurrences data by applying a group of functions from the package `CoordinateCleaner`. In this function, we also provide a way to check for environmental duplicates, by including a predictors object. This function also checks for records in the sea if the species is terrestrial, but note that this can be switched off if the studied species is not terrestrial. The way `caretSDM` works, we can always overwrite the main `input_sdm` object to update it. The function will return a new object with all the previous information and the new information obtained from the `data_clean` function, note that at the end of the Data Cleaning information there is the Duplicated Cell method. This method is only possible when we have both the `occurrence` and `predictors` data.

```{r data_clean}
i <- data_clean(i, capitals = FALSE)
i
```

### Removing multicolinearity from predictors' data

In `vif_predictors`, we are able to perform two methods to select variables: selecting all area or using the presence records (which is debatable, but implemented). `vif_predictors` allows for a maximum threshold to be informed. The standard is 0.5.

```{r vif_predictors}
i <- vif_predictors(i, th = 0.5, 
                    variables_selected = c("bio1", "bio2", "bio3", "bio4", "bio5", "bio6", "bio7", "bio12", "bio13", "bio14", "bio15")) 
i
```

### Obtaining pseudoabsence data

As we mentioned before, pseudoabsence data will be stored in the `occurrences` object (inside the `input_sdm`). To generate them, you can inform some parameters. The argument `variables_selected` will inform which variables you want to use to build your pseudoabsences/models. This can either be a vector of variables names or a previously performed selection method.

```{r pseudoabsence}
#### selecionar variáveis
i <- pseudoabsences(i, method = "bioclim", variables_selected = "vif") 
i
```

## Processing

### Modeling species relationship with variables

With the occurrences and predictors data put together, we can pass to the modeling. As the name suggests, `caretSDM` uses the `caret` package underlying its modeling procedure. For those who are not familiar, `caret` is the easiest way to perform Machine Learning analysis in R. It works by setting a modeling wrapper to pass multiple packages and can provide a lot of automation regarding algorithms fine-tuning, data spliting, pre-processing methods and predictions. These automated functions from `caret` can be altered using the `ctrl` argument in `train_sdm` function. See `?caret::trainControl` for all options available.

We show here how to use a repeated crossvalidation method, which is defined through `caret::trainControl`.

Note that, when you are using an algorithm for the first time, caret will ask you to install the relevant packages to properly run the algorithm.

```{r train_sdm, eval=TRUE}
ctrl_sdm <- caret::trainControl(method = "repeatedcv", 
                                number = 4, # Number of folds
                                repeats = 10, # Number of complete sets of folds to compute
                                classProbs = TRUE,
                                returnResamp = "all",
                                summaryFunction = summary_sdm,
                                savePredictions = "all")

i <- train_sdm(i, 
               algo = c("svmLinear2", "mda", "nnet", "kknn"), 
               crtl = ctrl_sdm, 
               variables_selected = "vif")
```

```{r train_sdm2}
i
```

```{r}
get_validation_metrics(i)
write_validation_metrics(i, path = "results")
```

## Post-Processing

### Predicting species distribution in given scenarios

Now that we have our models, we can make predictions in new scenarios. The function `predict_sdm` incorporates also the prediction of ensembles (`ensembles=TRUE` is standard).

```{r predict_sdm}
i <- predict_sdm(i, th = 0.9)
i
```

```{r}
write_ensembles(i, path = "results/ensembles", ext = ".tif")
write_ensembles(i, path = "results/ensembles", ext = ".csv", centroid = TRUE)
```

### Projecting models to future scenarios using chooseGCM

First, we need to use only one time period. Here we use 2090 so the difference between models is more conspicuous. In the same way we are considering the SSP585, which is the more dramatic pathway. The resolution is the lowest to be quicker. The aim here is to maintain all parameters equal, but General Circulation Models (GCMs). In this way we know that the only source of variation comes from them. Note that if you receive a timeout error you can increase timeout value by running , where 600 is the value in seconds that will be enough to download the data.

#### Importing and Transforming Data

Now let's import GCMs to R in a list of stacks and name the list with the names of the GCMs.

```{r import_gcms}
#s <- chooseGCM::import_gcms("input_data/WorldClim_data_chooseGCM")
s <- chooseGCM::import_gcms("/Users/luizesser/Documents/GitHub/input_data/WorldClim_data_future_all/")
names(s) <- gsub("_ssp585_10_2090", "", names(s))
```

In each following function, data will be transformed. To do that, you will always need to provide at least: (1) the list of stacks, (2) the variables you want to use in analysis and (3) the shapefile of your study area. You don't need to previously mask and subset your data, once the functions will perform this task internally for you. Note that the results from these functions are highly sensitive to variables and to study area. In this sense, the decision on what variables should be considered and what is the study area must be carefully made considering biological aspects of the studied group.

There is the option to run each function in separate to better understand what is happening and to better parameterize each step. However there is a wrapper to help run everything at once and could be an alternative to have a broad perspective. `compare_gcms()` will return a list with a vector called `suggested_gcms` and a Figure called `statistics_gcms`. We suggest that this Figure could also be included as it is in supplementary data from studies using this package.

```{r}
res <- chooseGCM::compare_gcms(s, var_names=c("bio01", "bio12"), sf::st_transform(get_sdm_area(i), crs=4326), k = 2)
res
```

The aim of this function is to inform the minimum required so users can follow with their workflow in a more straightforward fashion (more on each plot further). If we see the D plot in the Figure, we can infer if the selected GCMs encompass the environmental variety of all GCMs. The focus should be to cover the core environment and not outlier regions on the environmental space. Above that, in plot B, the Monte Carlo permutation between GCMs is presented as a violin plot. Plots A and C are both clusterization methods that can be used to select GCMs. Clusterization will be adapted to the number of clusters `k` designated in the function. Lastly, suggested GCMs were ch and in. Those suggestions are the gcms that are closer to the centroid of each K-means cluster, thus they better represent the variation within each cluster.

Now we can download data from WorldClim 2.1 to the selected GCMs:

```{r WorldClim_data_future2}
# Download future scenarios
#WorldClim_data(path="input_data/WorldClim_data_future/",period = "future", year = c('2050', '2090'), ssp = c('585'), gcm = res$suggested_gcms, resolution = 10)
# Import scenarios to R
scen <- stars::read_stars(list.files("input_data/WorldClim_data_future/", full.names = T), normalize_path = F)

# See what is inside pred_data
scen
```

### Add scenarios to the input_sdm

```{r}
i2 <- add_scenarios(i, scen)
i2
```

```{r}
i2 <- predict_sdm(i2, th = 0.9)
i2
```

```{r}
# Calculate GCM ensemble
i3 <- gcms_ensembles(i2, gcms=c("ch", "in"))
i3
```

```{r}
# Plot GCM ensemble:
plot_predictions(i3, scenario = "_ssp585_10_205")
```

```{r}
# Plot GCM ensemble:
plot_predictions(i3, scenario = "_ssp585_10_209")
```

### 
