---
title: "Projecting Non-native Distribution using SDMs"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Projecting Non-native Distribution using SDMs}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::knitr}
editor_options: 
  markdown: 
    wrap: 100
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

One of the main uses for Species Distribution Models is to project the impact of invasive species.
To facilitate the use of `caretSDM` in invasiveness assessments, we put this document together.
Here, we will build the Ecological Niche Model, i.e. the mathematical model that describes the
hypervolume that encompasses the limiting values permitting a species to persist through time, for
*Araucaria angustifolia* using records on Paran√°. We then project the models into the Rio Grande do
Sul state, further to the South, to assess the invasiveness potential of the species.

This article may read repetitive, when comparing with others, but our aim here is to have a complete
tutorial, thus some steps will be exactly as from other articles.

First, we need to open our library.

```{r setup}
library(caretSDM)
start_time <- Sys.time()
set.seed(1)
```

## Pre-Processing

To obtain models, we will need climatic data and species records. To easily obtain these data, we
have two functions: `WorldClim_data` function downloads climatic variables from WorldClim 2.1, a
widely used open-source database; in the same way, `GBIF_data` function downloads species records
from GBIF, also a widely used open-source database. You can read more about them by running in the
console `?GBIF_data` and `?WorldClim_data`.

### Obtaining species records

A easy way to get species data using `caretSDM` is the function `GBIF_data`, which retrieves species
records from GBIF. Understandably, there are other sources of species data available, as well as our
own data that can be the result of field work. In this sense, one can import to R it's own data in
multiple ways, but be sure that the table must always have three columns: species, decimalLongitude
and decimalLatitude. `GBIF_data` function can retrieve the data ready to be included in caretSDM,
thus if you have any doubt on how to format your own data, use `GBIF_data` function with the
parameter `as_df = TRUE` to retrieve an example table. As standard, `GBIF_data` function sets
`as_df = FALSE`, which makes the function return a `occurrences` object (more about that further
below). An example code for this step would be:

```{r gbif_data, eval = FALSE}
occ <- GBIF_data(c("Araucaria angustifolia"), as_df = TRUE)
```

But we already have a `occ` object included in the package, which is the same output, but with
filtered records to match our study area. Note that coordinates are in a metric CRS (EPSG: 6933).

```{r occ}
occ |> head()
```

### Obtaining climatic data

For climatic data, we will first download and import current data, which is used to build the
models. `WorldClim_data` function has an argument to set the directory in which you want to save the
files. If you don't set it, files will be saved in your working directory (run `getwd()` to find out
your working directory) in the folder "input_data/WorldClim_data_current/". If period is set to
"future", then it is saved in "input_data/WorldClim_data_future/". We could run this script with a
smaller resolution, but as the aim here is to show how the package works, we will use a resolution
of 10 arc-minutes, which is very coarse, but quicker to download and run.

```{r WorldClim_data_current, eval = FALSE}
# Download current bioclimatic variables
WorldClim_data(path = NULL, 
               period = "current", 
               variable = "bioc", 
               resolution = 10)

# Import current bioclimatic variables to R
bioc <- read_stars(list.files("input_data/WorldClim_data_current/", full.names = T), along = "band", normalize_path = F)
```

As we are aiming for a climate change assessment, we will also download future data.

```{r WorldClim_data_future, eval = FALSE}
WorldClim_data(path = NULL, 
               period = "future", 
               variable = "bioc",
               year = "2090",
               gcm = c("ca", "mi"),
               ssp = c("245","585"),
               resolution = 10)
```

#### KEY CHANGE FOR INVASIVENESS ASSESSMENT:

In caretSDM, we will set the study area to match the region where the model will be trained. The
region where models will be projected can be adapted from scenarios data. One can work around with
this environmental data to adapt it using any package. We already have included in the package an
object with current and future data for the Rio Grande do Sul state. To build it, we used an
adaptation of the following code:

```{r example_code, eval = FALSE}
# THIS IS AN EXAMPLE CODE, IT MUST BE ADAPTED TO RUN CORRECTLY!!!
# Import aim area shape
rs <- st_read("Rio_Grande_do_Sul.shp")

# Import current data
current <- read_stars(list.files("WorldClim_data_current_folder", full.names=T), along = "band")

# Change name of current scenario
names(current) <- "current"

# Select variables and crop using the shape of the aim area
current <- sf::st_crop(current[,,,c("1.tif", "4.tif", "12.tif")], rs)

# Set names of variables to match future scenario
current <- stars::st_set_dimensions(current, "band", values = c("bio1", "bio4","bio12"))

# Import future data
future <- read_stars(list.files("WorldClim_data_future_folder", full.names=T))

# Change names of future scenarios
names(future) <- c("ca_ssp245_2090", "ca_ssp585_2090", 
                   "mi_ssp245_2090", "mi_ssp585_2090")

# Select variables and crop using the shape of the aim area
future <- sf::st_crop(future[,,,c("bio01", "bio04", "bio12")], rs)

# Set names of variables to match current scenario
future <- stars::st_set_dimensions(future, "band", values = c("bio1", "bio4","bio12"))

# Sum scenarios
scen_rs <- c(current, future)
```

The result should resemble the included object (see `?scen_rs` for more information on the data).:

```{r scen_rs}
scen_rs
```

### Defining the study area

A important step on model building in Species Distribution Models, is the definition of accessible
area (the M in BAM diagram). This area can be, in Geographical Information Systems terms, as an
example, the delimitation of a habitat (polygon) or a river basin network (lines). Another broadly
used approach is the use of buffers around presences. The buffer size translates the potential
distribution capabilities of a species. As our invasiveness assessment aims to build models in the
Parana state and project in the Rio Grande do Sul state, we will use a simple polygon of Parana
state boundaries as study area. This shape is available in caretSDM as the `parana` object (see
`?parana` for more information on the data).

```{r parana_sf}
parana
```

```{r parana_view}
parana |> select_predictors(NOMEUF2) |> plot()
```

The `sdm_area` function is responsible to create a grid to build models, a key aspect of caretSDM
workflow. With a grid built, modelers can pass multiple rasters with different resolutions, CRSs and
extents. The package will be responsible to rescale, transform and crop every raster to match the
grid. The grid returned by the `sdm_area` function is from `sdm_area` class, a class that will also
keep the environmental/climatic data (*i.e.* "predictor variables", "covariates", "explanatory
variables", "features" or "control variables"). With this class we will perform analysis using only
the predictors. The grid is built using mostly the first three arguments: (1) a shape from `sf`
class, but rasters from `stars`, `rasterStack` or `SpatRaster` class are also allowed; (2) the cell
size of the grid; and (3) the Coordinate Reference System (CRS). Note that the cell size can be
metric or not depending on the CRS informed. It is important to inform a cell size bigger than the
coarser raster that will be used, otherwise rescaling process may return empty cells. The rescaling
can be performed using GDAL (quicker but less precise) or the `stars` package (slower but more
precise). The first will address values to cells by calculating the mean (for continuous variables)
or the median (for categorical variables) of the values falling within the cell. The approach using
`stars` will do the same thing, but weighting for the area of each value within the cell. For other
arguments meaning see `?sdm_area`.

```{r sdm_area}
sa <- sdm_area(parana, 
               cell_size = 25000, 
               crs = 6933, 
               variables_selected = NULL,
               gdal = TRUE, 
               crop_by = NULL, 
               lines_as_sdm_area = FALSE)
sa
```

Note that the function returned four predictor variables (`Predictor Names` above). These
"predictors" are actually columns included in the `parana` shape's data table. One can filter these
variables using `select_predictors` function, but we will not do that here, once the package will
automatically drop them further. You can explore the grid generated and stored in the `sdm_area`
object using the functions `mapview_grid()` or `plot_grid()`.

```{r plot_sdm_area}
plot_grid(sa)
```

Now that we have a study area, we can assign predictor variables to it. To do that, we use the
`add_predictors` function, which usually will only use the fist two arguments, which are the
`sdm_area` build in the previous step and the `RasterStack`, `SpatRaster` or `stars` object with
predictors data. Note that `add_predictors` also has a `gdal` argument, which works as the previous
one in `sdm_area` function.

```{r add_predictors}
sa <- add_predictors(sa, 
                     bioc, 
                     variables_selected = NULL, 
                     gdal = TRUE)
sa
```

Predictors variables are used to train the models. After training the models, we need to project
models into scenarios. Currently, we don't have any scenario in our `sdm_area` object. We can
address the predictors data as the current scenario by applying the function `add_scenario` without
considering any other argument. This happens because the argument `pred_as_scen` is standarly set to
`TRUE`. However, in invasiveness assessments, we want to project models into another region. This
region was previously set as the `scen_rs` object.

```{r add_scenarios}
sa <- add_scenarios(sa, 
                    scen = scen_rs, 
                    scenarios_names = NULL,
                    pred_as_scen = FALSE,
                    variables_selected = NULL, 
                    stationary = NULL)
sa
```

It is common that modelers need to subset variables that will inform models. This can be due to
statistical artifacts that are common in quarter bioclimatic variables, or a causation subset,
aiming for those variables with causality effect on species distribution. The user may also want to
change scenarios names, predictors names or retrieve predictors data. For that there are a myriad of
functions that can be found in the package, most of them under the help files of the functions
`?add_predictors` and `?add_scenarios`, but also `?select_predictors`.

### Defining the occurrences set in the study area

As `caretSDM` has a strong GIS background, it is necessary to explicitly tell which CRS is your data
in. This will assure that every GIS transformation is correct. `occurrences_sdm` function creates a
occurrences class (*i.e.* "response variable", "target" or "label") that will be used in
occurrences' transformations and functions, as pseudoabsences generation. For a reference, GBIF data
is in crs = 4326, but our records stored in `occ` object is transformed to 6933 (see `?occ` for more
information on the data).

```{r occurrences_sdm}
oc <- occurrences_sdm(occ, crs = 6933)
oc
```

```{r plot_occurrences}
plot_occurrences(oc)
```

This next step assigns occurrences into a study area, excluding records outside the study area or
with NAs as predictors.

```{r join_area}
oc <- join_area(oc, sa)
```

### The `input_sdm` class

In `caretSDM` we use multiple classes to perform our analysis. Every time we perform a new analysis,
objects keep the information of what we did. Ideally, the workflow will have only one object
throughout it. The `input_sdm` class is the key class in the workflow, where every function will
orbitate. That class puts occurrences, predictors, scenarios, models and predictions together to
perform analysis that are only possible when two or more of these classes are available. First, we
create the object by informing the occurrences and the sdm_area.

```{r input_sdm}
i <- input_sdm(oc, sa)
i
```

### Data cleaning routine

As the first step in our workflow with the `input_sdm` object, we will clean our occurrences data by
applying a group of functions from the package `CoordinateCleaner`. In this function, we also
provide a way to check for environmental duplicates, by including a predictors object. This function
also checks for records in the sea if the species is terrestrial, but note that this can be switched
off if the studied species is not terrestrial. The way `caretSDM` works, we can always overwrite the
main `input_sdm` object to update it. The function will return a new object with all the previous
information and the new information obtained from the `data_clean` function, note that at the end of
the Data Cleaning information there is the Duplicated Cell method. This method is only possible when
we have both the `occurrence` and `predictors` data.

```{r data_clean}
i <- data_clean(i,
                capitals = TRUE,
                centroids = TRUE,
                duplicated = TRUE,
                identical = TRUE,
                institutions = TRUE,
                invalid = TRUE,
                terrestrial = TRUE)
```

### Removing multicolinearity from predictors' data

There are two main methods in the SDM literature to consider multicolinearity in predictors data.
One is the use of VIFs, which in `caretSDM` is performed using `vif_predictors`function. There,
users are able to perform variables selection through `usdm` package. The function is a wrapper for
`usdm::vifcor`, where variables are kept given a maximum threshold of colinearity. The standard is
0.5. Here is a example code for demonstration:

```{r vif_predictors}
i <- vif_predictors(i, 
                    th = 0.5, 
                    maxobservations = 5000, 
                    variables_selected = NULL)
```

### Obtaining pseudoabsence data

Pseudoabsence data will be stored in the `occurrences` object (inside the `input_sdm`). To generate
them, you must inform some parameters. Probably one of the most important arguments in this function
is the `method`. Currently, two methods are implemented: a "random", which takes random grid cells
as pseudoabsences; and a "bioclim" method, which creates a Surface Range Envelope (SRE) using
presence records, binarizes the projection of the SRE using the `th` threshold and then retrieves
pseudoabsences outside the envelope. The number of pseudoabsences created can be changed using the
`n_pa` parameter. When set to NULL, `n_pa` will be equal the number of occurrences (to avoid
imbalance issues). The number of sets of pseudoabsences is adjusted with the `n_set` parameter in
the function. The argument `variables_selected` will inform which variables you want to use to build
your pseudoabsences/models. This can either be a vector of variables names or a previously performed
selection method.

```{r pseudoabsence}
i <- pseudoabsences(i, 
                    method = "bioclim", 
                    n_set = 10,
                    n_pa = NULL,
                    variables_selected = "vif",
                    th = 0) 
i
```

## Processing

### Modeling species relationship with variables

With the occurrences and predictors data put together, we can pass to the modeling. As the name
suggests, `caretSDM` uses the `caret` package underlying its modeling procedure. For those who are
not familiar, `caret` is the easiest way to perform Machine Learning analysis in R. It works by
setting a modeling wrapper to pass multiple packages and can provide a lot of automation regarding
algorithms fine-tuning, data spliting, pre-processing methods and predictions. These automated
functions from `caret` can be altered using the `ctrl` argument in `train_sdm` function. See
`?caret::trainControl` for all options available.

We show here how to use a repeated crossvalidation method, which is defined through
`caret::trainControl`.

Note that, when you are using an algorithm for the first time, caret will ask you to install the
relevant packages to properly run the algorithm.

```{r train_sdm}
ctrl_sdm <- caret::trainControl(method = "repeatedcv", 
                                number = 4, 
                                repeats = 1, 
                                classProbs = TRUE,
                                returnResamp = "all", 
                                summaryFunction = summary_sdm, 
                                savePredictions = "all")

i <- train_sdm(i, 
               algo = c("naive_bayes", "kknn"), 
               variables_selected = "vif", 
               ctrl=ctrl_sdm) |> suppressWarnings()
i
```

## Post-Processing

### Predicting species distribution in given scenarios

Now that we have our models, we can make predictions in new scenarios. The function `predict_sdm`
incorporates also the prediction of ensembles (`ensembles=TRUE` is standard). The function will only
predict models that passes a given validation threshold. This validation metric is set using
`metric` and `th` arguments. In the following example, metric is set to be "ROC" and th is equal
0.9. This means that only models with ROC \> 0.9 will be used in predictions and ensembles.

```{r predict_sdm}
i <- predict_sdm(i,
                 metric = "ROC",
                 th = 0.9,
                 tp = "prob",
                 ensembles = TRUE)
i
```

In the above print, it is possible to see the "Methods" under the "Predictions" section, which
informs which ensemble types were made: mean occurrence probability (`mean_occ_prob`; a simple mean
between GCMs), mean occurrence probability weighted by AUC/ROC (`wmean_AUC`; AUC/ROC values are used
as weights), and the majority rule, or the committee average (`committee_avg`; the sum of binaries).

Besides the AUC/ROC metric, users can get every available metric by model using the following code
before commit to "ROC":

```{r val_metrics}
get_validation_metrics(i)
```

Otherwise, the mean validation metric values per algorithm can also be obtained with the following
code:

```{r mean_val_metrics}
mean_validation_metrics(i)
```

After building predictions, it is possible to ensemble GCMs using `gcms_ensembles` function and
informing in the parameter `gcms` which part of `scenarios_names(i)` should be used to ensemble
gcms. In this example, scenarios names are:
`c("ca_ssp245_2090", "ca_ssp585_2090", "mi_ssp245_2090", "mi_ssp585_2090")`. Thus, if we set the
parameter to `c("ca", "mi")` the function searches through scenarios names for `"ca"` and `"mi"` and
remove these parts of scenarios names. What remains, in the example, is:
`c("_ssp245_2090", "_ssp585_2090", "_ssp245_2090", "_ssp585_2090")`. Then, the function ensembles
scenarios with the same new names (note that, by removing the gcms abbreviation, the remaining name
repeats itself two times). At the end, ensembles will be named after the new names generated in this
last step and are included in object `i` scenarios.

```{r gcms_ensembles}
i <- gcms_ensembles(i, gcms = c("ca", "mi"))
i
```

Note that now the section "Predictions" has two scenarios called \_ssp245_2090 and \_ssp585_2090,
which are the GCM's ensembles that we have calculated.

### Plotting results

To plot results, we prepared plot and mapview functions. Here we present only the plot versions due
to mapview limitations for markdown, but we encourage users to use the mapview alternatives every
time it is possible. To do that, simply alternate the "plot" portion of functions to "mapview". As
an example, `plot_occurrences` has its counterpart function `mapview_occurrences` with the same set
of arguments an functioning. For plot_predictions, we can set some parameters to control what is
being plotted. Probably the most important parameter is the `scenario`, which user can change to
plot every different scenario projected. If you are modeling more than one species you can inform
the correct species to be plotted using the `spp_name` parameter and if you are wealling to debate
separate projections you can plot them informing the model `id` (see row names of
`get_validation_metrics` above to retrieve models ids).

```{r plot_current_results}
plot_predictions(i,
                 spp_name = NULL,
                 scenario = "current",
                 id = NULL,
                 ensemble = TRUE,
                 ensemble_type = "mean_occ_prob")
```

```{r ssp245_2090}
plot_predictions(i,
                 spp_name = NULL,
                 scenario = "mi_ssp245_2090",
                 id = NULL,
                 ensemble = TRUE,
                 ensemble_type = "mean_occ_prob")
```

Another plot widely used in SDM studies is the Partial Dependence Plot, which informs the response
curves to each variable. Here we are using PCA axes as predictors, so there is not much sense in
plotting these curves, but if someone want to do that, it is possible through the `pdp_sdm`
function.

```{r pdp_sdm}
pdp_sdm(i)
```

### Writing results

To export `caretSDM` objects and outputs from R you can use the write functions. For all
possibilities see the help file `?write_ensembles`. We encourage users to use standard path
configuration, which organizes outputs in a straightforward fashion. Common functions are the
following:

```{r write_results, eval = FALSE}
write_occurrences(i, path = "results/occurrences.csv", grid = FALSE)
write_pseudoabsences(i, path = "results/pseudoabsences", ext = ".csv", centroid = FALSE)
write_grid(i, path = "results/grid_study_area.gpkg", centroid = FALSE)
write_ensembles(i, path = "results/ensembles", ext = ".tif")
```

## Conclusion

This vignette demonstrates how to build Species Distribution Models using `caretSDM`. This vignette
aimed to terrestrial uses highlights the use of the package using a grid in the sdm_area.
Alternative to that can be seen in vignettes("Salminus", "caretSDM") where we build SDMs for a fish
species using river lines in a simplefeatures object instead of cells in a grid.

```{r rmd_time}
end_time <- Sys.time()
end_time - start_time
```
