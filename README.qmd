---
title: "caretSDM"
author: "Lu√≠z Fernando Esser"
format: gfm
editor: visual
---

# caretSDM

`caretSDM` is a under development R package that uses the powerful `caret` package as the main engine to obtain Species Distribution Models. As `caret` is a packaged turned to build machine learning models, `caretSDM` has a strong focus on this approach.

## Installing

First we will install the package from github. For that we will need to install the `devtools` package first and then install the `caretSDM` package.

```{r, eval=F}
install.packages(setdiff("devtools", rownames(installed.packages())))
install_github('luizesser/caretSDM')
options(timeout = 600)
```

```{r}
library(caretSDM)
library(stars)
```

## Pre-Processing

### Obtaining example data

Now we will create some example data. Starting with occurrences and then predictors data. The first one is a function to obtain species data from GBIF, while the second is a function to obtain climatic variables from WorldClim 2.1. You can read more about them by running in the console `?GBIF_data` and `?WorldClim_data`.

```{r get_gbif_data}
#occ_data <- GBIF_data("Araucaria angustifolia")
occ_data <- read.csv('input_data/spp_data.csv')
```

```{r get_wc_data, eval=F}
pred_data <- WorldClim_data(period = 'current', resolution=10)
```

### The `input_sdm` class

In this package we will use multiple classes to perform our analysis. Every time we use those objects to perform some kind of analysis, the object will keep the information of what we did. Ideally, the workflow will have only one object throughout it. The `input_sdm` class is the key class in the workflow, where every function will orbitate. That class puts occurrences, predictors, scenarios, models and predictions together to perform analysis that are only possible when two or more of these classes are available. First, we create the object by informing the occurrences, predictors and scenarios classes.

The first class we will use is the occurrences class (*i.e.* "response variable", "target" or "label"). This class receives the occurrence data of the species. But, despite most species data available is presence-only, we consider here in this package that occurrence data is composed of two classes: presences and absences. If absences are not available in species data (which is expected), we will build multiple sets of pseudo-absences to be used in substitution. These datasets will be stored under `occurrences` in `input_sdm`.

Parallel to the `occurrences` class, we will have the `predictors` class to receive the environmental/climatic data (*i.e.* "predictor variables", "covariates", "explanatory variables", "features" or "control variables"). With this class we will perform analysis using only the predictors (such as geoprocessing transformations; `rescaling` argument) and together with the `occurrences` class (such as variable selection routines). It is important to say that this package has a strong geoprocessing background. In this way, it is possible to declare your study area using a shapefile, but also create a new grid over the study area by applying a rescaling method. This can also provide new EPSG to the data to avoid latidudinal convergence.

`input_sdm` function also receives a `scenarios` object, where the researcher can provide new data to project the models. This data can be from future or past scenarios. One can also provide a new `study_area` if the aim of the modeling is to project a model in a new area (*e.g.* as in invasiveness assessments). Lately, when projecting the models, we can include the predictors data as new data to be projected on. This is useful for projecting models in the same region where the model was built.

It is possible to pass multiple classes to the `occurrences`, `predictors` and `scenarios` functions as rasterStacks (from raster package), SpatRaster (from terra package), stars (from stars package), data.frames, simple features (sf package) and others. In this way, if you want to import data to R in your own way and then work them with your favorite package your are able to pass it to `caretSDM` afterwards. We propose here the use of the directory to enter data into caretSDM. By passing the directory to the predictors and scenarios functions, they will recognize data in folder and import it as stars objects (all the processing with geographic data in `caretSDM` is done using `stars` and `sf` packages).

```{r input_sdm}
# folder containing the current data downloaded from WorldClim.
folder_current <- "~/Documents/GitHub/caretSDM/input_data/WorldClim_data_current"

# folder containing the future data downloaded from WorldClim.
folder_future <- "~/Documents/GitHub/caretSDM/input_data/WorldClim_data_future"

# importing the study area and informing the crs. 
study_area <- st_read('input_data/Amazon/AmazonHydroRivers4.shp')
#st_crs(study_area) <- st_crs(4326)

# create the input_sdm that we will work with during the workflow.
i <- input_sdm(occurrences(occ_data), 
               predictors(folder_current, 
                          study_area = study_area,
                          rescaling=list(cellsize=100000, epsg=6933)), 
               scenarios(folder_future,
                         study_area = study_area,
                         rescaling=list(cellsize=100000, epsg=6933)))
i
```

**TIP:** pay attention on the information printed above. As we follow this tutorial, information will get richer.

### Data Cleaning

As the first step in our workflow, we will clean our occurrences data by applying a group of functions from the package `CoordinateCleaner`. In this function, we also provide a way to check for environmental duplicates, by including a predictors object. This function also checks for records in the sea if the species is terrestrial, but note that this can be switched off if the studied species is not terrestrial. The way `caretSDM` works, we can always overwrite the main `input_sdm` object to update it. The function will return a new object with all the previous information and the new information obtained from the `data_clean` function, note that at the end of the Data Cleaning information there is the Duplicated Cell method. This method is only possible when we have both the `occurrence` and `predictors` data.

```{r input_sdm_data_clean}
i <- data_clean(i)
i
```

**TIP:** Note that the information regarding the `i` object changed. Now it includes the information that we performed a Data Cleaning routine and explicitly informs what methods were used.

### Variable Selection

In `vif_predictors`, we are able to perform two methods to select variables: selecting all area or using the presence records (which is debatable, but implemented).

```{r input_sdm_vif_predictors}
i <- vif_predictors(i, area='all')
i
```

### Generate Pseudoabsences

As we mentioned before, pseudoabsence data will be stored in the `occurrences` object (inside the `input_sdm`). To generate them, you can inform some parameters. The argument `variables_selected` will inform which variables you want to use to build your pseudoabsences/models. This can either be a vector of variables names or a previously performed selection method.

```{r pseudoabsences}
i <- pseudoabsences(i, method='bioclim', variables_selected='vif')
i 
```

**TIP:** Note, again, that the information regarding the `i` object has increased. Now it includes the information that we performed a Data Cleaning routine, explicitly informing what methods were used, the information regarding VIF routine and the pseudoabsences.

We can test if our pseudoabsences are significantly different from the presences by ploting the t-SNE:

```{r tsne}
tsne_sdm(i, variables_selected='vif')
```

## Processing

With the occurrences and predictors data put together, we can pass to the modeling. As the name suggests, this package uses the `caret` package underlying its modeling procedure. For those who are not familiar, `caret` is the easiest way to perform Machine Learning analysis in R. It works by setting a modeling wrapper to pass multiple packages and can provide a lot of automation regarding algorithms fine-tuning, data spliting, pre-processing methods and predictions. These automated functions from `caret` can be altered using the `ctrl` argument in `train_sdm` function. See `?caret::trainControl` for all options available.

Note that, when you are using an algorithm for the first time, caret will ask you to install the relevant packages to properly run the algorithm.

```{r input_sdm_train2, include=F, eval=T}
i <- train_sdm(i,  algo=c('svmLinear2','mda','nnet','nb', 'kknn'), variables_selected='vif')
i
# Under development stacked method:
#i <- train_sdm(i,  algo=list(c('svmLinear2', 'fda'),c('svmLinear2')), #variables_selected='vif')
```

```{r input_sdm_train, eval=FALSE}
i <- train_sdm(i,  algo=c('svmLinear2','mda','nnet','nb', 'kknn'), variables_selected='vif')
i
# Under development stacked method:
#i <- train_sdm(i,  algo=list(c('svmLinear2', 'fda'),c('svmLinear2')), #variables_selected='vif')
```

Check mean validation metrics:

```{r model_metrics}
mean_validation_metrics(i)
```

See Variable importance:

```{r varImp}
varImp_sdm(i)
```

## Prediction

Now that we have our models, we can make predictions in new scenarios. The function `predict_sdm` incorporates also the prediction of ensembles (`ensembles=TRUE` is standard), as well as the prediction on current data (obtained from predictors data; `add.current=TRUE` is standard).

```{r input_sdm_predictions}
i <- predict_sdm(i)
i
```

## Mapping

To generate maps in caretSDM we can simply plot the input_sdm object. The plot function will look for ensembles, predictions, models and occurrences to be ploted, in this order. In this way, if only occurrences are available, it will plot the occurrences. If ensembles are available, it will plot the ensembles. You can specify what to plot using the `what` argument.

```{r generating_maps}
plot(i$predictions)
```

Alternatively, one could retrieve caretSDM data to its favorite class to work on:

```{r retrieving data}
st <- sdm_as_stars(i)
st
plot(st['mean_occ_prob'])
ter <- sdm_as_terra(i)
ter
r <- sdm_as_raster(i)
r
```
